# -*- coding: utf-8 -*-
"""analyze_pandas

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MSLZg2pvruowGjRnnbPiHjmTB58aCb86
"""

# -*- coding: utf-8 -*-

#!/usr/bin/env python3
"""
Анализ зарплат IT-специалистов с использованием Pandas
Задача: найти среднюю зарплату по уровню опыта
"""
import pandas as pd
import sys
import os
import subprocess

def check_hdfs_file_exists(hdfs_path):
    """Проверить существование файла в HDFS"""
    try:
        result = subprocess.run(
            f"hdfs dfs -test -e {hdfs_path}",
            shell=True,
            capture_output=True,
            text=True
        )
        return result.returncode == 0
    except Exception:
        return False

def copy_to_hdfs(local_path, hdfs_path):
    """Скопировать файл из локальной файловой системы в HDFS"""
    try:
        # Создаем директорию в HDFS если не существует
        hdfs_dir = os.path.dirname(hdfs_path)
        subprocess.run(
            f"hdfs dfs -mkdir -p {hdfs_dir}",
            shell=True,
            capture_output=True
        )

        # Копируем файл
        result = subprocess.run(
            f"hdfs dfs -put -f {local_path} {hdfs_path}",
            shell=True,
            capture_output=True,
            text=True
        )
        return result.returncode == 0
    except Exception:
        return False

def load_data_from_hdfs(hdfs_path):
    """Загрузить данные из HDFS"""
    try:
        # Создаем временный локальный файл
        temp_file = "/tmp/salary_data_temp.csv"

        # Копируем файл из HDFS в локальную файловую систему
        copy_command = f"hdfs dfs -get {hdfs_path} {temp_file}"
        result = subprocess.run(copy_command, shell=True, capture_output=True, text=True)

        if result.returncode != 0:
            return None

        # Загружаем данные из временного файла
        df = pd.read_csv(temp_file, low_memory=False)

        # Удаляем временный файл
        os.remove(temp_file)

        return df

    except Exception:
        # Пытаемся удалить временный файл в случае ошибки
        try:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        except:
            pass
        return None

def load_data(filepath):
    """Загрузить данные из CSV файла (HDFS или локальный)"""
    try:
        # Загружаем из HDFS
        if filepath.startswith('/user/hadoop/'):
            return load_data_from_hdfs(filepath)
        else:
            # Локальный файл
            if os.path.exists(filepath):
                return pd.read_csv(filepath, low_memory=False)
            else:
                return None
    except Exception:
        return None

def clean_data(df):
    """Очистка и подготовка данных"""
    print("\n=== Очистка данных ===")
    print(f"Исходное количество строк: {len(df)}")

    # Удалить строки без зарплаты
    df = df[df['salary_in_usd'].notna()]

    # Заполнить пустые значения в experience_level
    df['experience_level'] = df['experience_level'].fillna('Unknown')

    # Расшифровка кодов уровней опыта
    experience_map = {
        'EN': 'Entry-level',
        'MI': 'Mid-level',
        'SE': 'Senior-level',
        'EX': 'Executive-level',
        'Unknown': 'Unknown'
    }
    df['experience_level_name'] = df['experience_level'].map(experience_map)

    print(f"Количество строк после очистки: {len(df)}")
    print(f"Уникальных уровней опыта: {df['experience_level'].nunique()}")

    return df

def analyze_salary_by_experience(df):
    """Анализ зарплаты по уровням опыта"""
    print("\n=== Анализ зарплаты по уровням опыта ===")

    # Группировка по уровню опыта и вычисление статистики по зарплате (без медианы)
    result = df.groupby(['experience_level', 'experience_level_name'])['salary_in_usd'].agg([
        'mean', 'count', 'std', 'min', 'max'
    ]).reset_index()

    result.columns = [
        'Experience_Code', 'Experience_Level', 'Mean_Salary_USD',
        'Count', 'Std_Deviation', 'Min_Salary', 'Max_Salary'
    ]

    # Сортировка по средней зарплате
    result = result.sort_values('Mean_Salary_USD', ascending=False)

    return result

def find_salary_statistics(df):
    """Статистика зарплат по уровням опыта"""
    result = analyze_salary_by_experience(df)

    print("\n=== Результаты анализа зарплат ===")
    print("\nУровни опыта по средней зарплате:")
    print(result.to_string(index=False, float_format='%.2f'))

    max_salary_level = result.iloc[0]
    min_salary_level = result.iloc[-1]

    print(f"\nСамая высокооплачиваемая категория: '{max_salary_level['Experience_Level']}' ({max_salary_level['Experience_Code']})")
    print(f"Средний доход по категории: ${max_salary_level['Mean_Salary_USD']:,.2f} USD")
    print(f"Количество специалистов данной категории: {int(max_salary_level['Count'])}")
    print(f"Диапазон зарплат в данной категории: ${max_salary_level['Min_Salary']:,.2f} - ${max_salary_level['Max_Salary']:,.2f} USD")

    print(f"\nНаименее оплачиваемая категория: '{min_salary_level['Experience_Level']}' ({min_salary_level['Experience_Code']})")
    print(f"Средний доход по категории: ${min_salary_level['Mean_Salary_USD']:,.2f} USD")
    print(f"Количество специалистов данной категории: {int(min_salary_level['Count'])}")
    print(f"Диапазон зарплат в данной категории: ${min_salary_level['Min_Salary']:,.2f} - ${min_salary_level['Max_Salary']:,.2f} USD")

    return result

def additional_analysis(df):
    """Дополнительный анализ данных"""
    print("\n=== Дополнительная статистика ===")

    # Общая статистика по зарплатам
    print(f"\nОбщая статистика зарплат:")
    print(f"Средняя зарплата: ${df['salary_in_usd'].mean():,.2f}")
    print(f"Минимальная зарплата: ${df['salary_in_usd'].min():,.2f}")
    print(f"Максимальная зарплата: ${df['salary_in_usd'].max():,.2f}")

    # Распределение по уровням опыта
    print(f"\nРаспределение по уровням опыта:")
    experience_counts = df['experience_level_name'].value_counts()
    for level, count in experience_counts.items():
        percentage = (count / len(df)) * 100
        print(f"  {level}: {count} специалистов ({percentage:.1f}%)")

def main():
    # Используем точный путь
    data_file = '/user/hadoop/input/salary_data.csv'

    print("=== Анализ зарплат в Data Science ===")

    # Проверим файл в HDFS
    if not check_hdfs_file_exists(data_file):
        print(f"Ошибка: Файл не найден в HDFS: {data_file}")
        sys.exit(1)

    # Загрузка данных
    df = load_data(data_file)

    if df is None:
        print("Ошибка: Не удалось загрузить данные из HDFS")
        sys.exit(1)

    print(f"Успешно загружено строк: {len(df)}")

    # Очистка данных
    df_clean = clean_data(df)

    # Основной анализ
    result = find_salary_statistics(df_clean)

    # Дополнительный анализ
    additional_analysis(df_clean)

    # Сохранить результаты локально
    local_output_file = 'results/salary_by_experience.csv'
    os.makedirs('results', exist_ok=True)
    result.to_csv(local_output_file, index=False)
    print(f"\nРезультаты сохранены локально в: {local_output_file}")

    # Сохранить результаты в HDFS
    hdfs_output_file = '/user/hadoop/output/salary_by_experience.csv'
    if copy_to_hdfs(local_output_file, hdfs_output_file):
        print(f"Результаты также сохранены в HDFS: {hdfs_output_file}")
    else:
        print("Не удалось сохранить результаты в HDFS")

    return result

if __name__ == '__main__':
    main()